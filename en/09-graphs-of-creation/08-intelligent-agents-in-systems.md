---
title: Intelligent Agents in Systems
---

A human, as well as an AI-robot within systems, is considered complexly because
they **simultaneously** can be

-   a target system ("product")
-   a supersystem, where it is often more convenient to consider not the whole
    person, but a part of them—part of the body::hardware or skill as part of the personality::software,
-   material "equipment" like a machine in the composition of the creator (if
    they make something with hands/manipulators, and various hammers and chisels,
    and even modelers here are just extensions of their hands or
    brain/computer),
-   constructive/"material body" with its weight and inertia,
    moisture and hardness (as, for example, in considering inertial
    movement in bodily practices or robotics or in the example with
    wristwatches),
-   a project role, or even a whole set of project roles: we may not
    consider the opinions and interests of animals (although that is also bad), but we
    fundamentally cannot ignore the opinions of people in roles, we are forced
    to consider AI decisions and even just computer programs (remember
    "I would help, but the computer doesn't allow me"), and also decisions of organizations
    as "legal entities."

People and organizations also have subordination/leadership relationships and
property relations concerning things, and people (and organizations, and also
AI agents) hold certain positions. And they also "belong" to some
states. With agents, everything is immediately complicated: agents are complex, their behavior
is poorly predictable, they are difficult to describe. Before dividing
the complex thinking of the project among different agents (today it's not only
people!), we recommend modeling and documenting what you
know about agents to avoid getting confused and forgetting something. About people,
their AI systems, teams, and collectives (teams of teams), organizations
(enterprises and expanded/extended enterprises) you will think and write unexpectedly a lot, thinking about intelligent agents and
their groups is not the simplest. At even higher levels
of complexity, these will be levels of communities (including
business ecosystems), societies, and humanity (given the variety of
agents, it would be more correct to call it "agen-ciety") as a whole.

People can negotiate with each other for the most unexpected reasons and
undertake actions based on these agreements that are most unexpected for the
project team, though with the best intentions. For example, you
commission a manufacturer to make a copper heat exchanger based on your 3D engineering model.
The engineers of this factory suddenly find that there's too much copper, and they
remove some copper with the best intentions—less material consumption, thinner
walls, better heat exchange! And they manufacture an "improved version, our improvements—it's our bonus to you." You turn on
the heat exchanger, the thin walls under the pressure of the liquid start to hum
louder than a concert organ! The heat exchanger became a vibration generator,
a noise source! What a bonus! "They meant well, but it turned out as always"—this is quite a
common phenomenon in projects for creating and
developing systems, hence any changes have the status of a "hypothesis,"
you must always be prepared for the "hypothesis not being confirmed." And yet
without "initiative from below" projects will not thrive!

The best management and engineering methods (for example, the culture of architectural
work) are just such that inevitable errors, inevitable mutations do not
lead to the loss of system functionality, and the need
to redo the system from scratch. These methods/ways/practices are examined
in detail in the courses "Systems Engineering" (especially concerned with the method
of continuous architectural decision-making during an engineering project)
and "Systems Management."

Agents, including collective agents, usually participate in
several teams simultaneously, each occupied with several projects for
creating and developing systems. We remember that in the area of interest (a set of
objects of interest in some one subject area) for each
role performed by an agent, there are not just
preferences for certain interesting characteristics, but the agents performing these roles
will change their roles, change themselves (developing both body and exo-body,
and developing personality, mastering new types of skill), changing
the surrounding physical world to realize these preferences. Agents
(people, AI agents, their organizations) are devilishly inventive in achieving
their preferred state of the world. They will influence the course
of the system creation project and the resulting system in the most
unexpected ways for each other. Someone::agent will engineer the target
system without losing functionality, someone will arrange additional funding, someone will negotiate such a change in the supersystem that the target one will be cheaper. And someone will pull off a fraud hoping that either no one will notice, or will notice—
but will not be able to do anything without significant damage to the noticer. Agents
are inventive and active. Look in the mirror: you are such an agent,
all the others are hardly worse!

An example of a system with included people was already discussed in our course—
it's a dance performance/output. **The process unfolding in
time** **of changing states of the performance** **is set** **at the
system level below** **as a list** **of changing states**
**of interacting physical objects included in it,** **and these objects are highlighted by attention** **during the performance.** It is not necessary to stop the interaction of parts-subsystems of the
performance and disassemble the performance::system into constructs during
operation/functioning (trying to imagine an
explosion diagram), it's not necessary to disassemble the system, but to highlight parts with attention in the working system.

A dance performance can quite be imagined as a system, only it should
be imagined in space-time, not just in space.
The main functional parts-subsystems here will be dancing::function
dancers::roles/subsystems. In the performance, people-agents act both as
material/construct (physical bodies changing shape in space-time),
and as functional objects—project roles of dancers. Dance performance doesn't possess the complexity of an enterprise and
thereby doesn't require consideration of complex issues of corporate
management, strategizing, operational management/operation management.
Dance performances can be solo, and social
(pair, for each other, not for spectators), and group/ensemble.
Apart from the dancers, the location of the performance needs to be considered (venue or even
street for street performances), spectators, sometimes judges (dance
competitions), music, and sound equipment. Even non-people dance sometimes,
sometimes it's cyborgs (such as a dancer with additional four robotic
arms in a backpack^[<https://vk.com/wall-179019873_1747>]).
It's an excellent example to practice your systems
thinking^[Texts about dancing and systems thinking
are published in <https://vk.com/buffdance>].

Events are also classic examples of systems with people.
Methods of event management (event
management^[<https://en.wikipedia.org/wiki/Event_management>])
have even become a university discipline—creating and developing
(for example, conducting a concert tour) a concert or an annual rock festival
is difficult but nothing unusual today.

It is quite possible to consider thousands of people as part of the event system,
you can consider a series of events (for example, an annual festival) as
manufacturing continuously developing versions of a system in
mechanical engineering or releasing software versions. We deliberately use
engineering terminology ("manufacture a concert," "release a festival"),
to show the commonality of thinking for various systems. Of course, in
event management different terminology is used, but the choice of words/terms
is not that important here. What is important is that when thinking about
events, you choose system thinking types and use
the understanding of how they manufacture successful systems from systems
engineering. The very methods/practices of work (work culture, work style,
activity, method—the terms here are not important) in event management
will be given in applied courses, but linking together all this thinking about various
sub-projects (for example, negotiating with sound engineers,
negotiating about ventilation, etc.—purely engineering
sub-projects) can be based on using system thinking.
It's important to pay attention to the general style of reasoning in all projects
related to creating systems involving agents (people, AI-robots,
and even organizations) as subsystems.

A household, where there is a house with utensils and its residents (including
robots), and the previously discussed case of a clothing and gadgets consumer—these
are all examples of systems with human agents.

The most complex systems involving people and AI agents are such group
**creators/enabling/constructor** **systems** as enterprises, project workgroups,
extended enterprises (extended enterprise,
enterprise with its contractors, dealing with some big target
system, for example, a nuclear power plant, or mass production
of complex transport systems—aircraft or cars).

**Systems with people** **(including their organizations)---are**
**necessarily** **systems of systems because people have
the property of self-possession.** **Therefore, you cannot work with systems with people in them** **using simple engineering methods,** **with which** **you can construct a simple mechanical or mechanical
system with electronic elements, manufacture its parts, and assemble them into a functional whole.** No, **the metaphor of the watchmaker** with fabricating parts and assembling them does not work. With people (as with any other living
"grown" systems, and also trained AI systems) they rather use **agricultural** **metaphors:**

-   in small systems of systems of a **gardener** (who has control
    over what is being created, manages to take care of every sprout in
    every flowerbed, knows the position of every tree and cares for them),
-   in large systems of systems of a **forester** (who does not have
    control over their forest—where which tree or bush will grow, but still,
    a forester has enough influence to prevent some
    serious negative events: can prevent a fire, feed
    animals in winter, drive away poachers).

In especially large systems (a large community, society on the scale of
a state, all of humanity) sometimes they don't just talk about the
**complexity** of the system, but of **complexity thinking**^[See literature in P.K.Hrechko "Complexity Thinking: Methodological Prospects. Paradigmatic heuristic of complexity in modern social-humanitarian knowledge",
<https://journals.rudn.ru/philosophy/article/view/11283/10713>],
which does not allow actions with predictable results—
the outcomes of projects dealing with a large number of people are always
to a significant extent uncertain, they are described probabilistically, although
deterministically (deterministically means there is no place for “randomness,” there are always causes, but predicting the outcome is not possible^[Distinguishing random and deterministic in physics:
<https://arxiv.org/abs/1507.03287>]). One must always
remember that evolution creates complexity, generates ever higher levels
of organization, and the driving force of this evolution—
conflicts between system levels, leading to
turmoils^[<https://elementy.ru/nauchno-populyarnaya_biblioteka/434505/Konflikty_kak_osnova_slozhnosti>].

In especially large and complex systems of people, robots,
tools/equipment, that is, in communities (including communities of
enterprises—ecosystems), societies, humanity (considering all
other agents, "agen-ciety" suits better than "humanity") as
a whole, everything is so strongly interconnected and so unpredictably
the realization of one agent's intentions resists or assists
the realization of other agents' intentions, that "unexpectedness" is
the norm, the absence of surprises is practically non-existent, "best
solutions" do not exist, there are only "the least bad of known bad
ones."

**It's important to remember that one cannot design an enterprise or even a team and then fabricate them like a** **computer chip** **or a water tower. Systems with** **agents** **must be discussed using system thinking, but conceiving, creating,** **developing,** **operating, and eliminating them with classical** **"iron"** **or software engineering methods is ineffective, there it's necessary to use methods** **of training: engineering of personality for individual agents, systems management for collective** **agents (developing enterprises** **is essentially training new work methods for
collective agents).**

It's hard to imagine that the left booster on a rocket will conspire with
the right booster to fly not to Mars (where they should go), but to
the Moon—because it is more reliable and faster, there is certainly enough fuel, and it is less troublesome. But in a system of intelligent agents, this happens
all the time. **Be careful with the application of technical engineering methods** **for "iron"** **and "software"** **to systems with people** **and AI. At the same time, be cautious about the reverse situation—** **the non-application of common systems engineering** **methods, which are a generalization of precisely** **methods** **for working with** **"iron"** **and "software"** **to systems** **at all evolutionary/systemic/organizational levels (levels of complexity), including not only enterprise engineering, but also social engineering of the community, society, and even humanity as a whole.** Discussion of the consequences of this non-application can be found in the works of John Doyle^[<https://ailev.livejournal.com/1622346.html>].

Reasoning on the topic of systems with artificial intelligence (AI), starting from
a certain level of agency of such systems (the ability to generate
predictions of future states of themselves and the world, ideas for improving such
states, choosing the best of these ideas, and then planning and realizing
plans to bring these ideas to life), discussions about people, people in their
collectives, people in their collectives with AI (for example, enterprises)—are
one and the same reasoning, system thinking is scale-invariant and
non-anthropocentric.